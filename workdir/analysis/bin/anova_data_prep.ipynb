{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reduced_data = pd.read_csv(r\"../data/reduced_data_bin.csv\")\n",
    "df_encoded = reduced_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m df_encoded[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcaffeine_class\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Apply ANOVA F-test for feature importance (f_regression)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m F_values, p_values \u001b[38;5;241m=\u001b[39m \u001b[43mf_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create a DataFrame to store the F-values and p-values\u001b[39;00m\n\u001b[0;32m     11\u001b[0m anova_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: X\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF-Score\u001b[39m\u001b[38;5;124m'\u001b[39m: F_values,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp-Value\u001b[39m\u001b[38;5;124m'\u001b[39m: p_values\n\u001b[0;32m     15\u001b[0m })\n",
      "File \u001b[1;32mc:\\Users\\adm1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\adm1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:498\u001b[0m, in \u001b[0;36mf_regression\u001b[1;34m(X, y, center, force_finite)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    397\u001b[0m     {\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    404\u001b[0m )\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf_regression\u001b[39m(X, y, \u001b[38;5;241m*\u001b[39m, center\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, force_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    406\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Univariate linear regression tests returning F-statistic and p-values.\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \n\u001b[0;32m    408\u001b[0m \u001b[38;5;124;03m    Quick linear model for testing the effect of a single regressor,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03m    array([2.7..., 1.5..., 1.0...])\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 498\u001b[0m     correlation_coefficient \u001b[38;5;241m=\u001b[39m \u001b[43mr_regression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_finite\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m     deg_of_freedom \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m center \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    503\u001b[0m     corr_coef_squared \u001b[38;5;241m=\u001b[39m correlation_coefficient\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\adm1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adm1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:370\u001b[0m, in \u001b[0;36mr_regression\u001b[1;34m(X, y, center, force_finite)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# Compute centered values\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# Note that E[(x - mean(x))*(y - mean(y))] = E[x*(y - mean(y))], so we\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;66;03m# need not center X\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m center:\n\u001b[1;32m--> 370\u001b[0m     y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;241m-\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;66;03m# TODO: for Scipy <= 1.10, `isspmatrix(X)` returns `True` for sparse arrays.\u001b[39;00m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;66;03m# Here, we check the output of the `.mean` operation that returns a `np.matrix`\u001b[39;00m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;66;03m# for sparse matrices while a `np.array` for dense and sparse arrays.\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;66;03m# We can reconsider using `isspmatrix` when the minimum version is\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;66;03m# SciPy >= 1.11\u001b[39;00m\n\u001b[0;32m    376\u001b[0m     X_means \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\adm1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3596\u001b[0m, in \u001b[0;36mmean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m   3593\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3594\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3597\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adm1\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\_methods.py:140\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    138\u001b[0m         ret \u001b[38;5;241m=\u001b[39m ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(ret \u001b[38;5;241m/\u001b[39m rcount)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 140\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mret\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrcount\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'divide' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# Assuming 'target' is your continuous dependent variable (target)\n",
    "X = df_encoded.drop('caffeine_class', axis=1)\n",
    "y = df_encoded['caffeine_class']\n",
    "\n",
    "# Apply ANOVA F-test for feature importance (f_regression)\n",
    "F_values, p_values = f_regression(X, y)\n",
    "\n",
    "# Create a DataFrame to store the F-values and p-values\n",
    "anova_results = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'F-Score': F_values,\n",
    "    'p-Value': p_values\n",
    "})\n",
    "\n",
    "# Sort by F-score to see the most important features\n",
    "anova_results = anova_results.sort_values(by='F-Score', ascending=False)\n",
    "print(anova_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
